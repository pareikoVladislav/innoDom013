<!-- TOC -->
* [**Docker intro**](#docker-intro)
* [**Containerization - history**](#containerization---history)
* [**Docker emergence**](#docker-emergence-)
* [**Docker**](#docker-)
* [**Basic concepts and architecture of Docker**](#basic-concepts-and-architecture-of-docker-)
* [**Installing Docker on different platforms**](#installing-docker-on-different-platforms)
  * [**Windows**](#windows)
  * [**Unix**](#unix-)
* [**Working with images and containers**](#working-with-images-and-containers-)
* [**Docker Compose**](#docker-compose-)
* [**Docker-compose**](#docker-compose--1)
* [**Core settings of docker-compose**](#core-settings-of-docker-compose)
* [**Compose file commands hierarchy**](#compose-file-commands-hierarchy-)
* [**Dockerfile**](#dockerfile-)
* [**Dockerfile commands**](#dockerfile-commands)
<!-- TOC -->

# **Docker intro**

# **Containerization - history**

В целом в нашем мире достаточно долго уже играет такое понятие, как\
**контейнеризация**. Думаю все мы в той или иной мере работали с приложениями\
основанными на этом процессе. Что же это за процесс такой?

`Контейнеризация` — это метод виртуализации, при котором приложения и их зависимости\
**упаковываются в контейнеры**. Это позволяет легко и надёжно запускать приложения в\
разных вычислительных средах. Преимущества контейнеризации включают:

`Изоляция ресурсов`: Каждый контейнер имеет свои собственные ресурсы, включая\
операционную систему, и изолирован от других контейнеров.

`Легковесность`: Контейнеры требуют меньше ресурсов, чем традиционные виртуальные\
машины, поскольку они **делят ядро ОС хоста**, а **не требуют полноценной ОС**.\

`Переносимость`: Приложения в контейнерах можно легко переносить между различными\
системами и облачными платформами.

`Непрерывная интеграция и развертывание`: Упрощает процесс разработки, тестирования\
и развертывания приложений.


Думаю все помнят те времена, когда интернет уже появился, какие-либо различные\
фильмы \ программы \ игры на дисках стоили достаточно прилично, или же по\
каким-то причинам дискавода на ПК вовсе не было и все сидели, и скачивали\
какие-то "странные" `ISO-образы`, которые нужно было открывать через специальные\
программы. Одной из таких програм выступала `DEAMON-tools`

Это было достаточно популярное программное обеспечение для эмуляции оптических дисков\       
и виртуальных приводов. Оно позволяло создавать нам виртуальные копии\
`CD` и `DVD`-дисков, сохраняя их в виде образов на жёстком диске, словно обманывая\
наш компьютер, что диск есть, хотя на самом деле у нас был только "образ" диска.

Так же были такие программки, как `Virtual CloneDrive`, `Alcohol 120%:`, `PowerISO`\
и другие.

Эти мощные и удивительные приложения положили крепкое начало для развития систем,\
которые представили возможность перехода от эмуляции физических носителей к\
созданию виртуальных.

# **Docker emergence**                                                  

**К чему же это всё?**

У разработчиков в своё время была достаточно занятная, хоть и большая проблема:

Один разработчик мог начинать работу над написанием какой-то системы на своей ОС,\
со своими какими-то внутренними настройками системы, драйверами, со своими совместимостями\
между библиотеками, со своей ОС в конце концов. И возникала крайне неприятная проблема\
при передаче этого функционала другому разработчику и так же, что ещё более\
геморно было - клиенту. Тут же начинался какой-то сумасшедший каскад ошибок\
с совместимостями, код не запускался, всё, везде и на всё ругалось. Крайне сложно\
было настраивать проект при передаче его другому разрабу. Некоторые вещи\
приходилось настраивать фактически с нуля, находить в интернете аналоги библиотек\
для определённой системы, или же для определённой версии определённой системы.\
Всё это тратило уйму драгоценного времени для разработчиков и иногда выходило\
боком компаниями в плане отношений с заказчиком.

И вот, звёзды сошлись так, что в какой-то момент таки начали задумываться\
программисты, как проблему решить можно, ведь времени отнимается много, стресса\
много, неудобств много, клиентов недовольных так же много, а хотелось бы,\
чтобы этого не было всего. В те времена (лихие 00-ые) разработчики некоторые\
и обратили своё внимание на удивительно интересную систему работы контейнеризирующих\
приложений, которыми пользовались различные подростки для того, чтобы установить\
себе очередную игру без диска как такового.

Система была и правда удивительна и тут идея и появилась: "А почему бы не сделать\
что-то подобное в рамках приложения. Создавть какую-то програму, которая позволит\
упаковать наш продукт в своего рода упаковку, только дополнительно прокидывать и все\
дополнительные утилиты, библиотеки, даже саму операционную систему?"

Это было начало появления прекрасной технологии, как `Docker`

`Docker` — это не просто следующий шаг в виртуализации; это революционный подход,\
который **обеспечивает консистентность среды** на всех этапах разработки, тестирования\
и развертывания. Он позволяет разработчикам "упаковывать" свои приложения в\
контейнеры, **гарантируя**, что они **будут работать одинаково в любой среде**.


# **Docker**                                                 

В целом `docker` - это платформа для разработки, доставки и запуска\
приложений в контейнерах. Он позволяет упаковывать приложения со всеми\
их зависимостями в стандартизированные единицы для\
разработки и развертывания.

Основные функции `Docker` включают:

`Создание контейнеров`: `Docker` позволяет создавать контейнеры, которые\
запускают приложения в изолированной среде.

`Управление образами`: `Docker` использует образы для создания контейнеров.\
Образы можно создавать, хранить и распространять среди систем.

`Docker Hub и реестры`: `Docker Hub` — это облачный репозиторий, где можно\
хранить и распространять образы `Docker`.

`Docker Compose`: Инструмент для определения и запуска много-контейнерных\
приложений `Docker`.

---

# **Basic concepts and architecture of Docker**                                                       

Для улучшения понимания структуры и архитектуры `Docker`, важно правильно представлять\
и понимать зависимости между различными его компонентами.

**Docker Engine** — основа всей архитектуры `Docker`, представляющая собой\
клиент-серверное приложение. Он обеспечивает основной функционал для создания\
и управления контейнерами и состоит из сервера (демона `dockerd`) и клиентских\
интерфейсов (`CLI` и `REST`).

**Docker Daemon (dockerd)**: Это серверная часть **Docker Engine**, которая создает,\
запускает и управляет контейнерами `Docker`. Daemon общается с\
клиентами через `Docker API`.

**Docker Client**: Это клиентская часть Docker, через которую пользователи\
взаимодействуют с Docker Engine.
Пользователи используют командную строку или другие инструменты,\
взаимодействующие с Docker API.

**Docker Registry**: Это хранилище для `Docker` образов. Пользователи могут хранить\
образы в публичном или частном реестре, наиболее известным из которых\
является `Docker Hub`.

**Образы в Docker** — это шаблоны только для чтения, используемые для создания\
контейнеров. Образ содержит всё необходимое для запуска приложения: код,\
среду выполнения, библиотеки, переменные окружения и конфигурационные файлы.

**Контейнеры в Docker** — это изолированные среды, в которых запускаются приложения.\
Они создаются на основе образов и могут быть запущены, остановлены,\
перемещены и удалены.
Контейнеры делят ядро операционной системы хоста и изолируют процессы приложений\
от остальной системы, занимая значительно меньше ресурсов.


---

# **Installing Docker on different platforms**

## **Windows**

**Docker Desktop и WSL 2:**

**Системные требования**: Необходимо использовать Windows 10 или Windows 11 с\
поддержкой WSL 2. Рекомендуется использовать версию Windows 10 21H2 или\
выше для лучшей совместимости.

**Установка WSL 2**: Перед установкой `Docker Desktop` нужно убедиться, что у\
вас установлен и настроен `WSL 2`. Для этого могут потребоваться настройки\
в `BIOS`, включающие аппаратную виртуализацию.

**Установка Docker Desktop**: Скачайте и установите [Docker Desktop](https://www.docker.com/products/docker-desktop/), следуя\
инструкциям на официальном сайте [Docker](https://docs.docker.com/desktop/install/windows-install/). После установки убедитесь, что\
в настройках `Docker Desktop` активирована опция **"Use the WSL 2 based engine"**.


## **Unix**                                                 

**Выбор дистрибутива**: Проверьте, поддерживает ли ваш дистрибутив `Linux` установку\
`Docker` через пакетный менеджер. Большинство популярных дистрибутивов, таких\
как `Ubuntu`, `Debian`, `Fedora`, предлагают `Docker` в своих репозиториях.

**Установка**: Обычно установка выполняется командой вроде `sudo apt install docker-ce`\
(для `Debian`/`Ubuntu`) или `sudo yum install docker` (для `Fedora`). После установки\
необходимо запустить `Docker` сервис.

**Настройка и первый запуск**: Настройте `Docker` для запуска при старте системы и\
проверьте его работоспособность, запустив простой контейнер, например,\
`docker run hello-world`.

Более подробную, точную информацию можно всё так же найти на офф сайте: [Docker](https://docs.docker.com/engine/install/ubuntu/)

---

# **Working with images and containers**                                         

Разного рода образы для будущих работ можно найти на просторах такого сервиса,\
как `Docker HUB`. Грубо говоря это гигантский каталог всевозможных образов\
от разных разработчиков и даже компаний.

Для того, чтобы начать знакомиться с докером, выберем какой-нибудь образ и\
поставим его себе:

```commandline
sudo docker pull postgres:15-alpine3.18
```

Если всё будет окей - мы получим просто лог о процессе скачивания и сообщение\
об успешной загрузке, если всё будет хорошо.\

Далее, чтобы посмотреть список всех наших образов, доступных в системе, введём\
команду
```commandline
docker images
```
Эта команда покажет нам список всех доступных `docker`-образов на нашем устройстве.


Выглядеть это будет в формате таблицы:

| REPOSITORY  | TAG            | IMAGE ID   | CREATED     | SIZE         |
|-------------|----------------|------------|-------------|--------------|
| postgres    | 15-alphine3.18 | <image ID> | 5 weeks ago | <image size> |


Что и как у нас тут может выглядеть:

* `REPOSITORY` - содержит информацию о названии изображения
* `TAG` - тут обычно прописана версия вашего образа, который был скачан
* `IMAGE ID` - уникальный ID  изображения, который понадобится в будущих командах
* `CREATED` - дата создания образа. Обычно это дата создания не у вас на ПК,\
а на `Docker-HUB`
* `SIZE` - собственно размер образа

**Какие команды для работы имеются?**

`docker run`: Запускает новый контейнер. Например, `docker run hello-world`\
запускает контейнер с образом `hello-world`.

Распространённые флаги: `-d` (**detached mode**), `-p` (**port mapping**),\
`--name` (**именование контейнера**).

`docker ps`: Показывает список запущенных контейнеров. Так же можно `docker ps -a`\
для просмотра всех контейнеров, включая остановленные.

`docker pull`: Скачивает образ из реестра. Например, `docker pull ubuntu`\
загрузит последнюю версию образа `Ubuntu`.

`docker stop/start`: Останавливает или запускает контейнер. Например,\
`docker stop container_name`.

`docker rm/rmi`: Удаляет контейнеры (`rm`) или образы (`rmi`). Например,\
`docker rm container_name` или `docker rmi image_name`.

`docker logs`: Показывает логи контейнера. Например, `docker logs container_name`.

`docker exec`: Запускает новую команду внутри запущенного контейнера. Например,\
`docker exec -it container_name bash` для входа в контейнер.

Так как в нашем случае мы пока что идём "в лоб" через терминал на обычном `docker`\
команда на запуск у нас будет следующая:

```commandline
sudo docker run -e POSTGRES_PASSWORD=password -e POSTGRES_USER=testuser -e POSTGRES_DB=testdb 454a43bd9642
```

**В этой команде:**

* `-e POSTGRES_PASSWORD=password` устанавливает пароль для суперпользователя `PostgreSQL`.
* `-e POSTGRES_USER=testuser` создает тестового пользователя `testuser`.
* `-e POSTGRES_DB=testdb` создает базу данных `testdb`


Если всё хорошо - мы увидем процесс инициализации окружения и поднятия образа

На основе нашего изображения будут созданы определённые контейнеры, нам среди них\
нужно найти наш, отвечающий за базу данных. ДЛя этого можем воспользоваться\
командой:

```commandline
docker ps -a
```
Флаг `-a` позволит нам посмотреть все доступные контейнеры. Как работающие, так\
и выключенные. Увидим мы примерно следующее:

| CONTAINER ID   | IMAGE      | COMMAND        | CREATED        | STATUS             | PORTS                            | NAMES          |
|----------------|------------|----------------|----------------|--------------------|----------------------------------|----------------|
| <container_id> | <image_id> | <some command> | <time created> | <container_status> | <container_ports>(inner & outer) | <verbose_name> |
| <container_id> | <image_id> | <some command> | <time created> | <container_status> | <container_ports>(inner & outer) | <verbose_name> |
| <container_id> | <image_id> | <some command> | <time created> | <container_status> | <container_ports>(inner & outer) | <verbose_name> |


Тут у нас следующее:

* `CONTAINER ID` - собственно, уникальный ID котейнера.
* `IMAGE` - уникальный ID изображения, на основе которого создан контейнер.
* `COMMAND` - команда, которая была выполнена при запуске контейнера. Эта команда\
может указываться в `Dockerfile`, или же передаваться при создании контейнера.
* `CREATED` - Время создания контейнера. Когда контейнер был впервые запущен.
* `STATUS` - Текущее состояние контейнера.
* `PORTS` - Список портов, которые были проброшены, или же открыты\
Показывает, какие порты контейнера связаны с портами хост-системы, что\
позволяет общаться с контейнером извне.
* `NAMES` - Уникальное имя контейнера. Мы можем обращаться по нему, ну или же по\
его ID. Имя генерируется автоматически системой `docker` под капотом.


ПОсле того, как нам выпал список всех доступных контейнеров мы можем взять ID\
контейнера с нашей базой и запустить именно его:

```commandline
docker start {CONTAINER ID}
```

Если процесс проходит хорошо - `docker` просто вернёт вам ID в терминал.\
После этого, если нам так нужно, мы можем в этот контейнер зайти:

```commandline
docker exec -it <container_name> bash
```

Эта команда, если всё отработает, отправит нас прямиком внутрь контейнера, где\
мы сможем что-то делать. Допустим, подключимся к нашей базе:

```commandline
SELECT * FROM user;
```

```commandline
psql -U testuser -d testdb
```

```postgresql
CREATE TABLE IF NOT EXISTS users (
    id BIGSERIAL PRIMARY KEY, 
    email VARCHAR(120) UNIQUE NOT NULL, 
    first_name VARCHAR(50) NOT NULL, 
    last_name VARCHAR(50) NOT NULL, 
    username VARCHAR(30), 
    phone VARCHAR(75), 
    is_staff BOOLEAN DEFAULT FALSE, 
    is_superuser BOOLEAN DEFAULT FALSE, 
    is_verified BOOLEAN DEFAULT FALSE, 
    is_active BOOLEAN DEFAULT TRUE, 
    date_joined TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP, 
    last_login TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

```postgresql
INSERT INTO users (
    email,
    first_name,
    last_name,
    username,
    phone,
    is_staff,
    is_superuser,
    is_verified
    )
VALUES (
    'admin.mail@gmail.com',
    'Test',
    'Admin',
    'tAdmin97',
    '+789456123',
    True,
    True,
    True
);
```

```postgresql
INSERT INTO users (
    email,
    first_name,
    last_name,
    username,
    phone,
    is_verified
    )
VALUES (
    'ord.user@yahoo.com',
    'Vadim',
    'Albertovich',
    'v.Albert',
    '+ 1 775 554 156 31',
    True
);
```

Для того, чтобы внутри контейнера выйти из режима работы с базой можно прописать
```commandline
exit;
```

Для прекращения работы контейнера же мы можем прописать
```commandline
docker stop <container id>
```

---

# **Docker Compose**                                                     

`Docker compose` - инструмент для определения и управления много-контейнерными\
приложениями `Docker`. Основные преимущества его использования включают:

**Упрощение управления**: `Docker Compose` позволяет определить и управлять **всеми**\
контейнерами приложения **в одном YAML-файле**, что упрощает оркестрацию и\
координацию различных сервисов.

**Эффективность сотрудничества**: Файлы конфигурации `Docker Compose` легко делиться\
и использовать, что облегчает совместную работу разработчиков\
и операционных команд.

**Быстрая разработка приложений**: `Compose` кэширует конфигурацию создания контейнера,\
что позволяет быстро вносить изменения в среду.

**Переносимость между средами**: `Docker Compose` поддерживает использование переменных,\
что позволяет адаптировать конфигурацию для различных сред.


**Как это всё может выглядеть в рамках вашего будущего приложения:**

В проекте у вас будет отдельно специальный файл, который будет называться `Dockerfile`

# **Docker-compose**                                                   

Собственно, если `dockerfile` мы прописываем для настройки образа, то контейнеры\
которые будут строиться по этому образу прописываются в `docker-compose.yml` файле.\

Файл `docker-compose.yml` использует формат `YAML` (`YAML Ain't Markup Language`),\
который представляет собой удобный для человека формат сериализации данных.\
`YAML` часто используется для конфигурационных файлов и данных, которые должны\
быть легко читаемыми пользователями.


# **Core settings of docker-compose**

Есть определённое количество общих настроек в этом файле, которые зачастую\
прописываются там:

* `version`: Указывает версию `Docker Compose` файла. Например, `version: '3'`.\
Версия `Docker Compose` определяет, какие функции и форматы файла поддерживаются.\
По мере развития `Docker Compose` вводятся новые функции и изменения в синтаксисе,\
поэтому важно указывать версию, чтобы обеспечить совместимость и правильное\
понимание файла `Docker Compose`.

* `services`: Определяет сервисы, которые необходимо запустить. Каждый сервис,\
в свою очередь, может иметь множество настроек.

* `build`: Определяет параметры для сборки образа `Docker`. Может включать контекст\
сборки и путь к `Dockerfile`.

* `image`: Указывает имя образа для использования или сборки.

* `ports`: Определяет порты, которые будут открыты и соединены. Например, `- "8000:8000"`\
означает перенаправление порта `8000` хоста на порт `8000` контейнера.

* `volumes`: Определяет тома для хранения данных вне жизненного цикла контейнера.

* `environment`: Устанавливает переменные окружения внутри контейнера.

* `depends_on`: Определяет зависимости между сервисами, гарантируя, что\
сервисы запускаются в определенном порядке.


Так же можно встретить и такие дополнительные настройки:

* `networks`: Определяет сети для взаимодействия контейнеров.

* `command`: Позволяет переопределить команду по умолчанию при запуске контейнера.

* `links`: Устаревшая опция, которая позволяет связывать контейнеры без\
необходимости определения сетей.

* `expose`: Открывает порты только между контейнерами, но не делает их\
доступными с хоста.

* `entrypoint`: Позволяет переопределить точку входа (entrypoint) образа.


# **Compose file commands hierarchy**                                                

Структура файла `docker-compose.yml` включает в себя несколько ключевых разделов:

`version`: Верхнеуровневый параметр, указывающий версию синтаксиса `Docker Compose`.

`services`: Главный раздел, под которым перечисляются все сервисы (контейнеры),
которые необходимо запустить.

```yaml
version: '3'
services:
  webapp:
    ...
  db:
    ...
```

Внутри каждого сервиса (`webapp`, `db` и т.д.) могут быть указаны следующие настройки:

* `image` или `build`: Определяют образ, который будет использоваться для контейнера.
* `ports`: Указывают настройки портов.
* `volumes`: Определяют тома для хранения данных.
* `environment`: Устанавливают переменные окружения.
* `depends_on`: Задают зависимости от других сервисов.\
И другие настройки, специфичные для каждого сервиса.
* `volumes`: Определяет тома, используемые в сервисах.

* `networks`: Определяет сети, которые используются для взаимодействия между контейнерами.

* `configs` и `secrets`: Опциональные разделы для управления конфигурациями и секретами.

Эти разделы создают иерархию, в которой каждый сервис определяется своим набором\
параметров. Важно понимать, что параметры внутри сервиса применяются только к\
этому сервису, в то время как параметры вне сервисов (например, `volumes` и `networks`\
на верхнем уровне) относятся ко всему `Compose`-проекту в целом.


```yaml
version: '3.8'

services:
  # Сервис для PostgreSQL
  db:
    image: postgres:latest
    environment:
      POSTGRES_USER: ${DB_USER_POS}        # Имя пользователя, берется из .env файла
      POSTGRES_PASSWORD: ${DB_PASSWORD_POS}    # Пароль, берется из .env файла
      POSTGRES_DB: ${DB_NAME_POS}          # Имя базы данных, берется из .env файла
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "54322:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER_POS}"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: ["docker-entrypoint.sh", "postgres"]

volumes:
  postgres_data:
```

---

# **Dockerfile**                                       

`Dockerfile` — это основной компонент в мире `Docker`, предназначенный для\
создания образов `Docker`. Он содержит набор инструкций и команд, которые `Docker`\
использует для сборки образа. Каждая команда в `Dockerfile` создает новый слой\
в образе, и каждый слой кэшируется, что ускоряет процесс сборки при\
повторных сборках.

**В `Dockerfile` обычно включаются следующие действия:**

1. Указание базового образа (`FROM`), от которого будет создан ваш образ.
2. Установка необходимых программ и зависимостей (`RUN`).
3. Копирование файлов и директорий из локальной файловой системы в образ\
(`COPY` или `ADD`).
4. Установка переменных среды (`ENV`).
5. Определение команды, которая будет выполнена при запуске контейнера\
(`CMD` или `ENTRYPOINT`).



```dockerfile
# Используем Ubuntu 20.04 как базовый образ
FROM ubuntu:20.04

# Устанавливаем Python
RUN apt-get update && apt-get install -y python3 python3-pip

# Устанавливаем рабочую директорию в контейнере
WORKDIR /app

# Копируем файлы требований и устанавливаем зависимости Python
COPY requirements.txt /app/
RUN pip3 install -r requirements.txt

# Копируем остальные файлы проекта в контейнер
COPY . /app/

COPY /dump/todo_back.sql /docker-entrypoint-initdb.d/

# Определяем команду для запуска миграций и тестов при старте контейнера
CMD ["sh", "-c", "python3 manage.py makemigrations && python3 manage.py migrate && python3 manage.py test"]

```

# **Dockerfile commands**

Команды в `Dockerfile` определяют различные этапы построения образа `Docker`.\
Вот некоторые из ключевых команд и их назначение:


* `FROM`: Задает базовый образ. Например, `FROM ubuntu:20.04` означает, что образ\
будет построен на основе `Ubuntu 20.04`.

* `RUN`: Выполняет команды в новом слое образа и создает новый слой. Используется\
для установки пакетов и выполнения других команд. Например,\
`RUN apt-get update && apt-get install -y python3 python3-pip`.

* `WORKDIR`: Устанавливает рабочую директорию внутри контейнера. Команда\
`WORKDIR /app` создает директорию `/app` и делает ее текущей рабочей директорией.

* `COPY`: Копирует файлы и папки из вашей локальной файловой системы в файловую\
систему контейнера. Например, `COPY . /app/` копирует все файлы из текущей\
директории (в вашей локальной системе) в `/app` в контейнере.

* `CMD`: Задает команду, которая будет выполнена при запуске контейнера.\
Например, `CMD ["sh", "-c", "python3 manage.py migrate && python3 manage.py test"]`.

Синтаксис `COPY` и `RUN` следует общему шаблону команд в `Dockerfile`: сначала\
указывается команда, затем ее параметры. В случае `COPY`, первый\
параметр — это путь к файлу или директории на хосте, а второй\
параметр — путь назначения в файловой системе контейнера.

Кроме этих команд, в `Dockerfile` могут использоваться и другие\
команды, например:

* `ENV`: Устанавливает переменные окружения.
* `EXPOSE`: Объявляет порты, которые должны быть открыты.
* `ENTRYPOINT`: Предоставляет команду и параметры, которые не могут быть\
переопределены при запуске контейнера.
* `VOLUME`: Создает точку монтирования для работы с постоянным хранилищем.
* `USER`: Устанавливает пользователя, от имени которого будет запущен контейнер.
* `ADD`: Похожа на `COPY`, но может распаковывать локальные `.tar` файлы и\
скачивать `URL-адреса` внутрь образа.


В общем случае, в проекте может быть один `Dockerfile` **на каждый сервис** или компонент\
приложения, и один `docker-compose.yml`, который описывает и координирует работу\
**всех контейнеров в проекте**. Однако возможны и другие варианты организации,\
в зависимости от конкретных потребностей проекта.

1. **Один `Dockerfile` на проект**: Это типичный подход, если весь проект состоит из\
одного основного приложения (например, веб-сервера `Django`). В `Dockerfile`\
описывается создание образа для этого приложения.

2. **Множество `Dockerfile`'ов в проекте**: Если у вас есть несколько независимых\
сервисов (например, веб-приложение `Django`, отдельный сервис для обработки\
задач в фоне, сервис для управления медиа-файлами и т.д.), то для каждого\
из них может быть создан свой `Dockerfile`.

```
папка проекта/:
    ├── модуль webapp/
    │   ├── Dockerfile # Dockerfile для веб-приложения Django
    │   └── ... # Другие файлы веб-приложения
    │
    ├── модуль worker/
    │   ├── Dockerfile # Dockerfile для фонового сервиса обработки задач
    │   └── ... # Другие файлы фонового сервиса
    │
    ├── docker-compose.yml # Общий docker-compose файл для координации контейнеров
    ├── .env # Файл с переменными окружения
    └── README.md
```


3. **Один `docker-compose.yml`**: Обычно используется один `docker-compose.yml` файл,\
который определяет, как контейнеры будут работать вместе. В этом файле\
вы можете настроить сети, тома и зависимости между контейнерами.

4. **Несколько `docker-compose.yml` файлов**: Иногда используются разные `docker-compose.yml`\
файлы для разных сред (например, разработка, тестирование, продакшн) или для\
различных аспектов одной среды (например, основные сервисы и сервисы для\
мониторинга). В таком случае файлы могут быть объединены при запуске с\
помощью флага `-f`.

```
папка проекта/:
    ├── модуль webapp/
    │   ├── Dockerfile # Dockerfile для веб-приложения Django
    │   └── ... # Другие файлы веб-приложения
    │
    ├── docker-compose.yml # Основной docker-compose файл для разработки
    ├── docker-compose.prod.yml # docker-compose файл для продакшена
    ├── docker-compose.test.yml # docker-compose файл для тестовой среды
    ├── .env # Файл с переменными окружения
    └── README.md
```


Таким образом, количество и структура `Dockerfile` и `docker-compose.yml` файлов\
в проекте зависят от архитектуры приложения и требований к развертыванию.
